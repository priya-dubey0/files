<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>rgpv syllabus - rgpv timetable Microsoft Word - MTECH CSDS SYLLABUS _1_</title><meta name="author" content="AcademicsOne"/><style type="text/css"> * {margin:0; padding:0; text-indent:0; }
 h1 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 13pt; }
 .s1 { color: black; font-family:Calibri, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 11pt; }
 .s2 { color: black; font-family:Calibri, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 11pt; }
 .p, p { color: black; font-family:Calibri, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; margin:0pt; }
 h3 { color: black; font-family:Calibri, sans-serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 10pt; }
 h2 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: bold; text-decoration: none; font-size: 11pt; }
 li {display: block; }
 #l1 {padding-left: 0pt; }
 #l1> li>*:first-child:before {content: " "; color: black; font-family:Symbol, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 li {display: block; }
 #l2 {padding-left: 0pt;counter-reset: d1 1; }
 #l2> li>*:first-child:before {counter-increment: d1; content: counter(d1, decimal)". "; color: black; font-family:Calibri, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 11pt; }
 #l2> li:first-child>*:first-child:before {counter-increment: d1 0;  }
 li {display: block; }
 #l3 {padding-left: 0pt;counter-reset: e1 1; }
 #l3> li>*:first-child:before {counter-increment: e1; content: counter(e1, decimal)". "; color: black; font-family:Calibri, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l3> li:first-child>*:first-child:before {counter-increment: e1 0;  }
 li {display: block; }
 #l4 {padding-left: 0pt;counter-reset: f1 1; }
 #l4> li>*:first-child:before {counter-increment: f1; content: counter(f1, decimal)". "; color: black; font-family:Calibri, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l4> li:first-child>*:first-child:before {counter-increment: f1 0;  }
 li {display: block; }
 #l5 {padding-left: 0pt;counter-reset: g1 1; }
 #l5> li>*:first-child:before {counter-increment: g1; content: counter(g1, decimal)". "; color: black; font-family:Calibri, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l5> li:first-child>*:first-child:before {counter-increment: g1 0;  }
 li {display: block; }
 #l6 {padding-left: 0pt;counter-reset: h1 1; }
 #l6> li>*:first-child:before {counter-increment: h1; content: counter(h1, decimal)". "; color: black; font-family:Calibri, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l6> li:first-child>*:first-child:before {counter-increment: h1 0;  }
 li {display: block; }
 #l7 {padding-left: 0pt;counter-reset: i1 1; }
 #l7> li>*:first-child:before {counter-increment: i1; content: counter(i1, decimal)". "; color: black; font-family:Calibri, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l7> li:first-child>*:first-child:before {counter-increment: i1 0;  }
 li {display: block; }
 #l8 {padding-left: 0pt;counter-reset: j1 1; }
 #l8> li>*:first-child:before {counter-increment: j1; content: counter(j1, decimal)". "; color: black; font-family:Calibri, sans-serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 #l8> li:first-child>*:first-child:before {counter-increment: j1 0;  }
</style><link rel="sitemap" type="application/xml" title="Sitemap" href="/sitemap.xml"></head><body><div style="display:flex;justify-content:flex-end;"><a href="#" target="_blank" download="" id="pdf-download-link"><button type="button" style="cursor:pointer;-webkit-appearance:button;color:#fff;background-color:#007bff;border-color:#007bff;display:inline-block;font-weight:400;text-align:center;white-space:nowrap;vertical-align:middle;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;border:1px solid transparent;padding:0.375rem 0.75rem;font-size:1rem;line-height:1.5;border-radius:0.25rem;transition:color .15s ease-in-out,background-color .15s ease-in-out,border-color .15s ease-in-out,box-shadow .15s ease-in-out;text-transform:none;overflow:visible;margin:0;font-family:inherit;" download>Download</button></a></div><script>const a=(window.location.pathname).split("/");const filename="" + a[a.length-1] + ".pdf";document.getElementById("pdf-download-link").href=filename;</script><h1 style="padding-top: 3pt;padding-left: 50pt;text-indent: 24pt;line-height: 202%;text-align: left;">Rajiv Gandhi ProudyogikiVishwavidyalaya Bhopal M.Tech Computer - Science and Engineering (Data Science)</h1><h1 style="padding-left: 68pt;text-indent: 0pt;text-align: center;">First Semester Syllabus</h1><p style="text-indent: 0pt;text-align: left;"><br/></p><h1 style="padding-left: 73pt;text-indent: 0pt;text-align: center;">MTCD 101-ComputationalLinearAlgebra</h1><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s1" style="padding-left: 13pt;text-indent: 0pt;text-align: left;">CourseObjectives</p><ul id="l1"><li data-list-text=""><p class="s2" style="padding-top: 8pt;padding-left: 47pt;text-indent: -17pt;line-height: 111%;text-align: left;">Thecoursewilllay downthebasicconceptsand techniquesoflinearalgebraandcalculusneededforsubsequent study.</p></li><li data-list-text=""><p class="s2" style="padding-left: 47pt;text-indent: -17pt;line-height: 109%;text-align: left;">Thecoursewillexploretheconceptsinitiallythroughcomputationalexperimentsandt hentrytounderstandthe conceptsand theory behind it.</p></li><li data-list-text=""><p class="s2" style="padding-left: 47pt;text-indent: -17pt;line-height: 111%;text-align: left;">Thecoursewillprovideanappreciationofthewideapplicationofthesedisciplineswithi nthescientificworld.</p></li></ul><p class="s1" style="padding-left: 7pt;text-indent: 0pt;line-height: 13pt;text-align: left;">Syllabus</p><p class="s1" style="padding-top: 9pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">UNIT I</p><p class="s2" style="padding-top: 4pt;padding-left: 13pt;text-indent: 0pt;line-height: 110%;text-align: justify;">Matrices and Gaussian Elimination – Introduction, geometry of linear equations, Gaussian elimination,matrix  multiplication,  inverses  and  transposes.Vector  spaces  and  Linear equations–Vector spaces and sub spaces, linear independence, basis and dimension, four fundamental subspaces.</p><p class="s1" style="padding-top: 3pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">UNIT II</p><p class="s2" style="padding-top: 5pt;padding-left: 13pt;text-indent: 0pt;line-height: 110%;text-align: left;">Orthogonality-Perpendicularvectorsandorthogonal  subspaces,innerproductsandprojectionsontolines,projectionsandleastsquareapplications,or  thogonalbasis,orthogonalspaces,orthogonalmatrices,GramSchmidtorthogonalization,FFT.</p><p class="s1" style="padding-top: 3pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">UNIT III</p><p class="s2" style="padding-top: 5pt;padding-left: 13pt;text-indent: 0pt;line-height: 110%;text-align: justify;">Probability, compound probability and discrete random variable. Binomial, Normal and Poisson’s distributions, Sampling distribution, elementary concept of estimation and theory of hypothesis, recurred relations.</p><p class="s1" style="padding-top: 3pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">UNIT IV</p><p class="s2" style="padding-top: 5pt;padding-left: 13pt;text-indent: 0pt;line-height: 110%;text-align: left;">EigenvaluesandEigenvectors– Introduction,diagonalformofamatrix,differenceequationsandthepowersofA^k,PositiveDefin iteMatrices-Minima,maximaandsaddlepoints,testsforpositivedefiniteness,semi- definiteandindefinitematrices,SingularValueDecomposition,Iterativemethods for Ax = b.</p><p class="s1" style="padding-top: 3pt;padding-left: 13pt;text-indent: 0pt;text-align: left;">UNIT V</p><p class="s2" style="padding-top: 5pt;padding-left: 13pt;text-indent: 0pt;line-height: 110%;text-align: justify;">Introduction  to  special  matrices  -  Fourier  transforms:  discrete  and  continuous, shiftmatrices and circulant matrices, Kronecker product, sine and cosine transforms from Kronecker sums, Toeplitz matrices and shift in variant filters, graphs and Laplacians and Kirchhoff&#39;       slaws,       clustering       by       spectralmethodsandk- means,completingrankonematrices,orthogonalProcrustesproblem,distancematrices</p><p class="s1" style="padding-top: 4pt;padding-left: 13pt;text-indent: 0pt;text-align: justify;">Textbook/ References</p><p class="s2" style="padding-top: 3pt;padding-left: 13pt;text-indent: 0pt;line-height: 110%;text-align: justify;">Gilbert Strang, Linear Algebra and its Applications, Fourth Edition, Cambridge University Press. 2009. Gene H. Golub and V. Van Loan, Matrix Computations, Third Edition, John Hopkins University Press, Baltimore, 1996.</p><p class="s2" style="padding-top: 3pt;padding-left: 13pt;text-indent: 0pt;text-align: justify;">David C. Lay, Linear Algebra and Its Applications, Pearson Addison Wesley, 2002.</p><p class="s2" style="padding-top: 5pt;padding-left: 13pt;text-indent: 0pt;line-height: 111%;text-align: justify;">Strang, Gilbert. Linear algebra and learning from data. Cambridge: Wellesley-Cambridge Press, 2019.</p><h1 style="padding-top: 3pt;padding-left: 74pt;text-indent: 0pt;text-align: center;">MTCD 102-Advanced data structures and Algorithm</h1><p class="s1" style="padding-top: 4pt;padding-left: 16pt;text-indent: -2pt;line-height: 138%;text-align: left;">Syllabus UNIT I</p><p class="s2" style="padding-left: 13pt;text-indent: 0pt;line-height: 111%;text-align: left;">INTRODUCTION: Basic concepts of OOPs – Templates – Algorithm Analysis – ADT - List (Singly, Doubly and Circular) Implementation - Array, Pointer, Cursor Implementation</p><p class="s1" style="padding-top: 3pt;padding-left: 16pt;text-indent: 0pt;text-align: justify;">UNIT II</p><p class="s2" style="padding-top: 5pt;padding-left: 13pt;text-indent: 0pt;line-height: 110%;text-align: justify;">BASIC DATA STRUCTURES: Stacks and Queues – ADT, Implementation and Applications - Trees  – General,  Binary,  Binary  Search,  Expression  Search,  AVL,  Splay,  B-Trees  – Implementations - Tree Traversals.</p><p class="s1" style="padding-top: 3pt;padding-left: 16pt;text-indent: 0pt;text-align: justify;">UNIT III</p><p class="s2" style="padding-top: 4pt;padding-left: 13pt;text-indent: 2pt;line-height: 111%;text-align: justify;">ADVANCED DATA STRUCTURES: Set – Implementation – Basic operations on set – Priority Queue – Implementation - Graphs – Directed Graphs – Shortest Path Problem - Undirected Graph - Spanning Trees – Graph Traversals</p><p class="s1" style="padding-top: 3pt;padding-left: 13pt;text-indent: 0pt;text-align: justify;">UNIT IV</p><p class="s2" style="padding-top: 5pt;padding-left: 13pt;text-indent: 0pt;line-height: 111%;text-align: justify;">MEMORY MANAGEMENT; Issues - Managing Equal Sized Blocks - Garbage Collection Algorithms for Equal Sized Blocks - Storage Allocation for Objects with Mixed Sizes - Buddy Systems - Storage Compaction</p><p class="s1" style="padding-top: 3pt;padding-left: 16pt;text-indent: 0pt;text-align: justify;">UNIT V</p><p class="s2" style="padding-top: 5pt;padding-left: 13pt;text-indent: 0pt;line-height: 109%;text-align: justify;">SEARCHING, SORTING AND DESIGN TECHNIQUES: Searching Techniques, Sorting – Internal Sorting – Bubble Sort, Insertion Sort, Quick Sort, Heap Sort, Bin Sort, Radix Sort – External Sorting – Merge Sort, Multi-way Merge Sort, Polyphase Sorting - Design Techniques - Divide and Conquer - Dynamic Programming - Greedy Algorithm – Backtracking - Local Search Algorithms</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s1" style="padding-left: 13pt;text-indent: 0pt;text-align: left;">Reference Books:</p><ol id="l2"><li data-list-text="1."><p class="s2" style="padding-top: 5pt;padding-left: 24pt;text-indent: -11pt;text-align: left;">Mark Allen Weiss, “Data Structures and Algorithm Analysis in C++”, Pearson P</p></li><li data-list-text="2."><p class="s2" style="padding-top: 5pt;padding-left: 24pt;text-indent: -11pt;text-align: left;">Aho, Hopcroft, Ullman, “Data Structures and Algorithms”, Pearson Education P</p></li><li data-list-text="3."><p class="s2" style="padding-top: 5pt;padding-left: 24pt;text-indent: -11pt;text-align: left;">Drozdek, Data Structures and algorithm in Jawa, Cengage (Thomson)</p></li><li data-list-text="4."><p class="s2" style="padding-top: 5pt;padding-left: 24pt;text-indent: -11pt;text-align: left;">Gilberg, Data structures Using C++, Cengage</p></li><li data-list-text="5."><p class="s2" style="padding-top: 5pt;padding-left: 24pt;text-indent: -11pt;text-align: left;">Horowitz, Sahni, Rajasekaran, “Computer Algorithms”, Galgotia,</p></li><li data-list-text="6."><p class="s2" style="padding-top: 5pt;padding-left: 13pt;text-indent: 0pt;line-height: 111%;text-align: left;">Tanenbaum A.S., Langram Y, Augestien M.J., “Data Structures using C &amp; C++”, Prentice Hall of India, 2002</p></li></ol><h1 style="padding-top: 3pt;padding-left: 73pt;text-indent: 0pt;text-align: center;">MTCD 103-Machine Learning</h1><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 7pt;text-indent: 0pt;text-align: left;">Course Outcomes:</p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">After completing the course student should be able to:</p><ol id="l3"><li data-list-text="1."><p style="padding-left: 20pt;text-indent: -10pt;text-align: left;">Describe in-depth about theories, methods, and algorithms in machine learning.</p></li><li data-list-text="2."><p style="padding-left: 20pt;text-indent: -10pt;text-align: left;">Find and analyze the optimal hyper parameters of the machine learning algorithms.</p></li><li data-list-text="3."><p style="padding-left: 7pt;text-indent: 0pt;text-align: left;">Examine the nature of a problem at hand and determine whether a machine learning can solve it efficiently enough.</p></li><li data-list-text="4."><p style="padding-left: 20pt;text-indent: -10pt;text-align: left;">Solve and implement the real-world problems using machine learning.</p></li></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 7pt;text-indent: 0pt;text-align: left;">Syllabus:</h3><h3 style="padding-left: 7pt;text-indent: 0pt;text-align: left;">UNIT I</h3><p style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;line-height: 111%;text-align: justify;">Introduction to machine learning (ML): Basics of ML, History of ML, Evolution of ML, ML Models, Learning and testing models, ML Algorithm and Convergence, MLTechniques, Types of ML, supervised and unsupervised learning, classification and clustering, Applications of ML,Bias-Variance tradeoff.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 7pt;text-indent: 0pt;text-align: left;">UNIT II</h3><p style="padding-top: 1pt;padding-left: 7pt;text-indent: 2pt;line-height: 111%;text-align: justify;">Neural Networks: McCulloch Pitts  Neuron  models,Activation Functions,  Loss  Functions, perceptron,Gradient Descent,Multilayer neural networks: back-propagation, backpropagation calculus, Initialization, Training rules, issues in back-propagation, Bayesian Learning,Competitive learning and self-organization map.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 10pt;text-indent: 0pt;text-align: left;">UNIT III</h3><p style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;line-height: 113%;text-align: justify;">Support Vector Machines(SVM):SVM Formulation, Interpretation &amp; Analysis, hard and soft margin, Hinge loss, SVM dual, SVM tuning parameters, SVM Kernels, twin SVM.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 7pt;text-indent: 0pt;text-align: left;">UNIT IV</h3><p style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;line-height: 111%;text-align: justify;">Clustering: K-Means Clustering, Mean Shift Clustering, Aagglomerative clustering, Association Rule Mining, Partition Clustering, Hierarchical Clustering, Birch Algorithm, CURE Algorithm, Density-based Clustering, Gaussian Mixture Models, and Expectation Maximization. Parameters estimations – MLE,MAP.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 7pt;text-indent: 0pt;text-align: left;">UNIT V</h3><p style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;line-height: 112%;text-align: justify;">Learning Theory: Probably Approximately Correct (PAC) Model, PAC Learnability, Agnostic PAC Learning, Theoretical analysis of machine learning problems and algorithms,Generalization error bounds,VC Model,MLTools.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 7pt;text-indent: 0pt;text-align: left;">Recommended Books:</h3><ol id="l4"><li data-list-text="1."><p style="padding-top: 1pt;padding-left: 17pt;text-indent: -10pt;text-align: left;">Tom Mitchell, Machine Learning, McGraw-Hill, 1997.</p></li><li data-list-text="2."><p style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;line-height: 112%;text-align: left;">Leonard Kaufman and P. J. Rousseau. Finding groups in data: An introduction to cluster analysis, Wiley, 2005</p></li><li data-list-text="3."><p style="padding-left: 7pt;text-indent: 0pt;line-height: 112%;text-align: left;">NelloCristianini and John Shawe-Taylor, An Introduction to Support Vector Machines,Cambridge University Press, 2000.</p></li><li data-list-text="4."><p style="padding-left: 17pt;text-indent: -10pt;text-align: left;">Bernhard Schölkopf and Alexander J. Smola, Learning with Kernels, MIT Press, 2002.</p></li><li data-list-text="5."><p style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;line-height: 113%;text-align: left;">Shai Shalev-Shwartz and Shai Ben-David, Understanding Machine Learning:From Theory to Algorithms, Cambridge University Press.,2014</p></li></ol><h1 style="padding-top: 3pt;padding-left: 68pt;text-indent: 0pt;text-align: center;">MDSCS104-DataScience</h1><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 7pt;text-indent: 0pt;line-height: 112%;text-align: justify;">Unit 1<span class="p">: Introduction to core concepts and technologies: Introduction Terminology, data science process, Data science toolkit, Types of data, Example applications.</span></h3><h3 style="padding-top: 7pt;padding-left: 7pt;text-indent: 2pt;line-height: 112%;text-align: justify;">Unit 2<span class="p">: Data collection and management: Introduction, Sources of data, Data collection and APIs. Exploring and fixing data. Data storage and management, Using multiple data sources.</span></h3><h3 style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;text-align: justify;">Unit 3<span class="p">. Data analysis: Introduction , Terminology and concepts. Introduction to statistics Variance</span></h3><p style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;line-height: 110%;text-align: justify;">,Distribution properties and arithmetic Samples/CLT, Basic machine learning algorithms ,Linear regression ,SVM, Naive Bayes.</p><h3 style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;line-height: 110%;text-align: justify;">Unit 4<span class="p">: Data Visualization: Introduction ,Types of data visualization, Data for visualization, Data types, Data encodings, Retinal variables, Mapping variables to encodings. Visual encodings.</span></h3><h3 style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;line-height: 112%;text-align: justify;">Unit 5<span class="p">: Applications of Data Science Technologies for visualization, Bokeh (Python) Recent trends in various data collection and analysis techniques various visualization techniques, application development methods of used in data science.</span></h3><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 7pt;text-indent: 0pt;text-align: justify;">REFERENCE BOOKS</h3><ol id="l5"><li data-list-text="1."><p style="padding-top: 8pt;padding-left: 17pt;text-indent: -10pt;text-align: left;">Cathy O’Neil and Rachel schutt ,Dong Data Science, Straight Talk from the Frontline. O&#39;Reilly.</p></li><li data-list-text="2."><p style="padding-top: 9pt;padding-left: 7pt;text-indent: 0pt;line-height: 110%;text-align: left;">Jure Leskovek, Anand Rajaraman and Jeffrey Ullman . Mining of Massive Datasets. V2.1. Cambridge University Press</p></li></ol><h2 style="padding-top: 3pt;padding-left: 68pt;text-indent: 0pt;text-align: center;">MTCD 105(A) Big Data</h2><p style="padding-top: 8pt;padding-left: 7pt;text-indent: 0pt;line-height: 111%;text-align: justify;">UNIT-I Introduction to Big Data. What is Big Data. Why Big Data is Important. Meet Hadoop. Data. Data Storage and Analysis. Comparison with other systems. Grid Computing. A brief history of Hadoop. Apache hadoop and the Hadoop EcoSystem. Linux refresher; VMWare Installation of Hadoop.</p><p style="padding-top: 8pt;padding-left: 7pt;text-indent: 0pt;line-height: 111%;text-align: justify;">UNIT-II The design of HDFS. HDFS concepts. Command line interface to HDFS. Hadoop File systems. Interfaces. Java Interface to Hadoop. Anatomy of a file read. Anatomy of a file write. Replica placement and Coherency Model. Parallel copying with distcp, Keeping an HDFS cluster balanced.</p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;line-height: 112%;text-align: justify;">UNIT-III (Introduction. Analyzing data with unix tools. Analyzing data with hadoop. Java MapReduce classes (new API). Data flow, combiner functions, Running a distributed MapReduce Job. Configuration API. Setting up the development environment. Managing configuration. Writing a unit test with MRUnit. Running a job in local job runner. Running on a cluster.Launching a job. The MapReduce WebUI.</p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;text-align: justify;">UNIT-IV Classic Mapreduce. Job submission. Job Initialization. Task Assignment. Task execution</p><p style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;line-height: 112%;text-align: justify;">.Progress and status updates. Job Completion. Shuffle and sort on Map and reducer side. Configuration tuning. MapReduce Types. Input formats. Output formats ,Sorting. Map side and Reduce side joins.</p><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;line-height: 111%;text-align: justify;">UNIT-V The Hive Shell. Hive services. Hive clients. The meta store. Comparison with traditional databases. HiveQl. Hbasics. Concepts. Implementation. Java and Mapreduce clients. Loading data, web queries.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 7pt;text-indent: 0pt;text-align: justify;">TEXT BOOKS:</p><ol id="l6"><li data-list-text="1."><p style="padding-top: 8pt;padding-left: 17pt;text-indent: -10pt;text-align: justify;">Tom White, Hadoop, “The Definitive Guide”, 3rd Edition, O’Reilly Publications, 2012.</p></li><li data-list-text="2."><p style="padding-top: 8pt;padding-left: 7pt;text-indent: 0pt;line-height: 112%;text-align: justify;">Dirk deRoos, Chris Eaton, George Lapis, Paul Zikopoulos, Tom Deutsch , “Understanding Big Data: Analytics for Enterprise Class Hadoop and Streaming Data”, McGrawHill Osborne Media; 1 edition, 2011.</p></li></ol><h2 style="padding-top: 3pt;padding-left: 68pt;text-indent: 0pt;text-align: center;">MTCD 105(B) Data Preparation and Analysis</h2><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-top: 10pt;padding-left: 7pt;text-indent: 0pt;line-height: 110%;text-align: left;">UNIT- I <span class="p">Data Gathering and Preparation: Data formats, Parsing and transformation, Scalability and real-time issues.</span></h3><h3 style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;line-height: 112%;text-align: left;">UNIT -II <span class="p">Data Cleaning: Consistency checking, Heterogeneous and missing data, Data Transformation and Segmentation.</span></h3><h3 style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;line-height: 112%;text-align: left;">UNIT -III <span class="p">Exploratory Analysis: Descriptive and comparative statistics, Clustering and association, Hypothesis Generation.</span></h3><h3 style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;line-height: 110%;text-align: left;">UNIT- IV <span class="p">Visualization: Designing visualizations, Time series, Geo located data, Correlations and Connections, Hierarchies and networks, interactivity.</span></h3><h3 style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;line-height: 111%;text-align: left;">UNIT- V<span class="p">Statistics : Descriptive statistics, Central tendency, Variation , Shape, Inferential statistics Confidence intervals, Hypothesis tests, Chi-square, One-way analysis of variance, Comparative statistics</span></h3><h3 style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;line-height: 112%;text-align: left;">References<span class="p">: 1. Making sense of Data : A practical Guide to Exploratory Data Analysis and Data Mining, by Glenn J. Myatt.,Wiley</span></h3><h2 style="padding-top: 3pt;padding-left: 68pt;text-indent: 0pt;text-align: center;">MTCD 105(C) Information Retrieval</h2><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 7pt;text-indent: 0pt;line-height: 111%;text-align: left;">UNIT-I <span class="p">Introduction - History of IR- Components of IR - Issues -Open source Search engine Frameworks - The Impact of the web on IR - The role of artificial intelligence (AI) in IR – IR Versus Web Search - Components of a search engine, Characterizing the web.</span></h3><h3 style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;line-height: 111%;text-align: left;">UNIT -II <span class="p">Boolean and Vector space retrieval models- Term weighting - TF-IDF weighting- cosine similarity - Preprocessing - Inverted indices - efficient processing with sparse vectors Language Model based IR - Probabilistic IR -Latent Semantic indexing - Relevance feedback and query expansion.</span></h3><h3 style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;line-height: 111%;text-align: left;">UNIT- III <span class="p">Web search overview, web structure the user paid placement search engine optimization, Web Search Architectures - crawling - meta-crawlers, Focused Crawling - web indexes – Nearduplicate detection - Index Compression - XML retrieval.</span></h3><h3 style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">UNIT -IV <span class="p">Link Analysis -hubs and authorities - Page Rank and HITS algorithms -Searching and Ranking</span></h3><p style="padding-top: 1pt;padding-left: 7pt;text-indent: 0pt;line-height: 112%;text-align: left;">- Relevance Scoring and ranking for Web - Similarity - Hadoop &amp; Map Reduce - Evaluation - Personalized search - Collaborative filtering and content-based recommendation of documents And products - handling invisible Web - Snippet generation, Summarization. Question Answering, Cross- Lingual Retrieval.</p><h3 style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;line-height: 112%;text-align: left;">UNIT -V <span class="p">Information filtering: organization and relevance feedback - Text Mining- Text classification and clustering - Categorization algorithms, naive Bayes, decision trees and nearest neighbor - Clustering algorithms: agglomerative clustering, k-means, expectation maximization (EM).</span></h3><h3 style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">References:</h3><ol id="l7"><li data-list-text="1."><p style="padding-top: 9pt;padding-left: 7pt;text-indent: 0pt;line-height: 110%;text-align: left;">C. Manning, P. Raghvan and H Schutze: Introduction to Information Retrieval, Cambridge University Press, 2008.</p></li><li data-list-text="2."><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;line-height: 110%;text-align: left;">Ricardo Baeza -Yates and Berthier Ribeiro –Neto, Modern Information Retrieval The Concepts and Technology behind Search 2nd Edition, ACM Press Books 2011.</p></li><li data-list-text="3."><p style="padding-top: 7pt;padding-left: 7pt;text-indent: 2pt;line-height: 112%;text-align: left;">Bruce Croft, Donald Metzler and Trevor Strohman Search Engines Information Retrieval in Practice 1st Edition Addison Wesley, 2009</p></li><li data-list-text="4."><p style="padding-top: 7pt;padding-left: 15pt;text-indent: -7pt;text-align: left;">Mark Levene, An Introduction to Search Engines and Web Navigation, 2nd Edition Wiley 2010.</p></li></ol><h2 style="padding-top: 3pt;padding-left: 97pt;text-indent: 0pt;text-align: center;">MTCD 105(D) Data Warehousing and Data Mining</h2><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 7pt;text-indent: 0pt;line-height: 112%;text-align: left;">UNIT 1 <span class="p">Introduction: Data Mining: Definitions, KDD v/s Data Mining, DBMS v/s Data Mining , DM techniques, Mining problems, Issues and Challenges in DM, DM Application areas. Association Rules &amp; Clustering Techniques: Introduction, Various association algorithms like A Priori, Partition, Pincer search etc., Generalized association rules.</span></h3><h3 style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;line-height: 110%;text-align: left;">UNIT 2 <span class="p">Clustering paradigms; Partitioning algorithms like K-Medioid, CLARA, CLARANS; Hierarchical clustering, DBSCAN, BIRCH, CURE; categorical clustering algorithms, STIRR, ROCK, CACTUS.</span></h3><h3 style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;line-height: 111%;text-align: left;">UNIT 3 <span class="p">Other DM techniques &amp; Web Mining: Application of Neural Network, AI, Fuzzy logic and Genetic algorithm, Decision tree in DM. Web Mining, Web content mining, Web structure Mining, Web Usage Mining.</span></h3><h3 style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;line-height: 112%;text-align: left;">UNIT 4 <span class="p">Temporal and spatial DM: Temporal association rules, Sequence Mining, GSP, SPADE, SPIRIT, and WUM algorithms, Episode Discovery, Event prediction, Time series analysis.</span></h3><h3 style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;line-height: 111%;text-align: left;">UNIT 5 <span class="p">Spatial Mining, Spatial Mining tasks, Spatial clustering, Spatial Trends, Data Mining of Image and Video: A case study. Image and Video representation techniques, feature extraction, motion analysis, content based image and video retrieval, clustering and association paradigm, knowledge discovery.</span></h3><h3 style="padding-top: 7pt;padding-left: 7pt;text-indent: 0pt;text-align: left;">Reference Books:</h3><ol id="l8"><li data-list-text="1."><p style="padding-top: 8pt;padding-left: 17pt;text-indent: -10pt;text-align: left;">Data Mining Techniques; Arun K.Pujari ; University Press.</p></li><li data-list-text="2."><p style="padding-top: 9pt;padding-left: 17pt;text-indent: -10pt;text-align: left;">Data Mining; Adriaans&amp;Zantinge; Pearson education.</p></li><li data-list-text="3."><p style="padding-top: 8pt;padding-left: 17pt;text-indent: -10pt;text-align: left;">Mastering Data Mining; Berry Linoff; Wiley.</p></li><li data-list-text="4."><p style="padding-top: 9pt;padding-left: 17pt;text-indent: -10pt;text-align: left;">Data Mining; Dunham; Pearson education. 5. Text Mining Applications, Konchandy, Cengage</p></li></ol></body></html>
